{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assessment1 (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Isrumk/Fundamentals-of-deep-learning-for-computer-Vision/blob/master/Assessment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g-atf3gekcgR"
      },
      "source": [
        "# Assessment 1: I can train and deploy a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_7wkT17FkmU6"
      },
      "source": [
        "At this point, you've worked through a full deep learning workflow. You've loaded a dataset, trained a model, and deployed your model into a simple application. Validate your learning by attempting to replicate that workflow with a new problem.\n",
        "\n",
        "We've included a dataset which consists of two classes:  \n",
        "\n",
        "1) Face: Contains images which include the face of a whale  \n",
        "2) Not Face: Contains images which do not include the face of a whale.  \n",
        "\n",
        "The dataset is located at ```/dli/data/whale/data/train```.\n",
        "\n",
        "Your challenge is:\n",
        "\n",
        "1) Use [DIGITS](/digits) to train a model to identify *new* whale faces with an accuracy of more than 80%.   \n",
        "\n",
        "2) Deploy your model by modifying and saving the python application [submission.py](../../../../edit/tasks/task-assessment/task/submission.py) to return the word \"whale\" if the image contains a whale's face and \"not whale\" if the image does not.  \n",
        "\n",
        "Resources:\n",
        "\n",
        "1) [Train a model](../../task1/task/Train%20a%20Model.ipynb)  \n",
        "2) [New Data as a goal](../../task2/task/New%20Data%20as%20a%20Goal.ipynb)  \n",
        "3) [Deployment](../../task3/task/Deployment.ipynb)  \n",
        "\n",
        "Suggestions: \n",
        "\n",
        "- Use empty code blocks to find out any informantion necessary to solve this problem: eg: ```!ls [directorypath] prints the files in a given directory``` \n",
        "- Executing the first two cells below will run your python script with test images, the first should return \"whale\" and the second should return \"not whale\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YaaY1Vb3o3mC"
      },
      "source": [
        "Start in [DIGITS](/digits/). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r56vtWlRVfrg",
        "colab_type": "code",
        "colab": {},
        "outputId": "4fa23b1b-303c-4fcf-f18e-757631b4138b"
      },
      "source": [
        "!python submission.py '/dli/data/whale/data/train/face/w_1.jpg'  #This should return \"whale\" at the very bottom"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0902 12:59:43.043836   398 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
            "I0902 12:59:43.044533   398 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11790385152, dev_info[0]: total=11996954624 free=11790385152\n",
            "W0902 12:59:43.044597   398 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
            "W0902 12:59:43.044710   398 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
            "W0902 12:59:43.044726   398 _caffe.cpp:175] Net('/dli/data/digits/20190902-120542-fbb4/deploy.prototxt', 1, weights='/dli/data/digits/20190902-120542-fbb4/snapshot_iter_1620.caffemodel')\n",
            "I0902 12:59:43.045053   398 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20190902-120542-fbb4/deploy.prototxt\n",
            "I0902 12:59:43.045084   398 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
            "W0902 12:59:43.045096   398 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
            "I0902 12:59:43.055333   398 net.cpp:79] Initializing net from parameters: \n",
            "state {\n",
            "  phase: TEST\n",
            "  level: 0\n",
            "}\n",
            "layer {\n",
            "  name: \"input\"\n",
            "  type: \"Input\"\n",
            "  top: \"data\"\n",
            "  input_param {\n",
            "    shape {\n",
            "      dim: 1\n",
            "      dim: 3\n",
            "      dim: 227\n",
            "      dim: 227\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 96\n",
            "    kernel_size: 11\n",
            "    stride: 4\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"conv1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"norm1\"\n",
            "  type: \"LRN\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"norm1\"\n",
            "  lrn_param {\n",
            "    local_size: 5\n",
            "    alpha: 0.0001\n",
            "    beta: 0.75\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"norm1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    group: 2\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0.1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"norm2\"\n",
            "  type: \"LRN\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"norm2\"\n",
            "  lrn_param {\n",
            "    local_size: 5\n",
            "    alpha: 0.0001\n",
            "    beta: 0.75\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"norm2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 384\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv4\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv4\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 384\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    group: 2\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0.1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu4\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv4\"\n",
            "  top: \"conv4\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv5\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"conv4\"\n",
            "  top: \"conv5\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    group: 2\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0.1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu5\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv5\"\n",
            "  top: \"conv5\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool5\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv5\"\n",
            "  top: \"pool5\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"fc6\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool5\"\n",
            "  top: \"fc6\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 4096\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.005\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0.1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu6\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"fc6\"\n",
            "  top: \"fc6\"\n",
            "}\n",
            "layer {\n",
            "  name: \"drop6\"\n",
            "  type: \"Dropout\"\n",
            "  bottom: \"fc6\"\n",
            "  top: \"fc6\"\n",
            "  dropout_param {\n",
            "    dropout_ratio: 0.5\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"fc7\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"fc6\"\n",
            "  top: \"fc7\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 4096\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.005\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0.1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu7\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"fc7\"\n",
            "  top: \"fc7\"\n",
            "}\n",
            "layer {\n",
            "  name: \"drop7\"\n",
            "  type: \"Dropout\"\n",
            "  bottom: \"fc7\"\n",
            "  top: \"fc7\"\n",
            "  dropout_param {\n",
            "    dropout_ratio: 0.5\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"fc8\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"fc7\"\n",
            "  top: \"fc8\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 2\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"softmax\"\n",
            "  type: \"Softmax\"\n",
            "  bottom: \"fc8\"\n",
            "  top: \"softmax\"\n",
            "}\n",
            "I0902 12:59:43.055768   398 net.cpp:109] Using FLOAT as default forward math type\n",
            "I0902 12:59:43.055785   398 net.cpp:115] Using FLOAT as default backward math type\n",
            "I0902 12:59:43.055799   398 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
            "I0902 12:59:43.055817   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.055842   398 net.cpp:199] Created Layer input (0)\n",
            "I0902 12:59:43.055864   398 net.cpp:541] input -> data\n",
            "I0902 12:59:43.056607   398 net.cpp:259] Setting up input\n",
            "I0902 12:59:43.056643   398 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
            "I0902 12:59:43.056663   398 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
            "I0902 12:59:43.056681   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.056720   398 net.cpp:199] Created Layer conv1 (1)\n",
            "I0902 12:59:43.056735   398 net.cpp:571] conv1 <- data\n",
            "I0902 12:59:43.056756   398 net.cpp:541] conv1 -> conv1\n",
            "I0902 12:59:43.630098   398 net.cpp:259] Setting up conv1\n",
            "I0902 12:59:43.630153   398 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
            "I0902 12:59:43.630198   398 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
            "I0902 12:59:43.630219   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.630246   398 net.cpp:199] Created Layer relu1 (2)\n",
            "I0902 12:59:43.630262   398 net.cpp:571] relu1 <- conv1\n",
            "I0902 12:59:43.630280   398 net.cpp:526] relu1 -> conv1 (in-place)\n",
            "I0902 12:59:43.630311   398 net.cpp:259] Setting up relu1\n",
            "I0902 12:59:43.630328   398 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
            "I0902 12:59:43.630344   398 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
            "I0902 12:59:43.630360   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.630395   398 net.cpp:199] Created Layer norm1 (3)\n",
            "I0902 12:59:43.630409   398 net.cpp:571] norm1 <- conv1\n",
            "I0902 12:59:43.630425   398 net.cpp:541] norm1 -> norm1\n",
            "I0902 12:59:43.630496   398 net.cpp:259] Setting up norm1\n",
            "I0902 12:59:43.630517   398 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
            "I0902 12:59:43.630534   398 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
            "I0902 12:59:43.630550   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.630633   398 net.cpp:199] Created Layer pool1 (4)\n",
            "I0902 12:59:43.630650   398 net.cpp:571] pool1 <- norm1\n",
            "I0902 12:59:43.630667   398 net.cpp:541] pool1 -> pool1\n",
            "I0902 12:59:43.630743   398 net.cpp:259] Setting up pool1\n",
            "I0902 12:59:43.630762   398 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
            "I0902 12:59:43.630781   398 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
            "I0902 12:59:43.630797   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.630833   398 net.cpp:199] Created Layer conv2 (5)\n",
            "I0902 12:59:43.630848   398 net.cpp:571] conv2 <- pool1\n",
            "I0902 12:59:43.630867   398 net.cpp:541] conv2 -> conv2\n",
            "I0902 12:59:43.638360   398 net.cpp:259] Setting up conv2\n",
            "I0902 12:59:43.638402   398 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
            "I0902 12:59:43.638435   398 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
            "I0902 12:59:43.638453   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.638476   398 net.cpp:199] Created Layer relu2 (6)\n",
            "I0902 12:59:43.638492   398 net.cpp:571] relu2 <- conv2\n",
            "I0902 12:59:43.638511   398 net.cpp:526] relu2 -> conv2 (in-place)\n",
            "I0902 12:59:43.638535   398 net.cpp:259] Setting up relu2\n",
            "I0902 12:59:43.638556   398 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
            "I0902 12:59:43.638572   398 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
            "I0902 12:59:43.638607   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.638640   398 net.cpp:199] Created Layer norm2 (7)\n",
            "I0902 12:59:43.638654   398 net.cpp:571] norm2 <- conv2\n",
            "I0902 12:59:43.638671   398 net.cpp:541] norm2 -> norm2\n",
            "I0902 12:59:43.638746   398 net.cpp:259] Setting up norm2\n",
            "I0902 12:59:43.638768   398 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
            "I0902 12:59:43.638787   398 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
            "I0902 12:59:43.638803   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.638828   398 net.cpp:199] Created Layer pool2 (8)\n",
            "I0902 12:59:43.638850   398 net.cpp:571] pool2 <- norm2\n",
            "I0902 12:59:43.638867   398 net.cpp:541] pool2 -> pool2\n",
            "I0902 12:59:43.638947   398 net.cpp:259] Setting up pool2\n",
            "I0902 12:59:43.638967   398 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
            "I0902 12:59:43.638984   398 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
            "I0902 12:59:43.639001   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.639036   398 net.cpp:199] Created Layer conv3 (9)\n",
            "I0902 12:59:43.639051   398 net.cpp:571] conv3 <- pool2\n",
            "I0902 12:59:43.639070   398 net.cpp:541] conv3 -> conv3\n",
            "I0902 12:59:43.655441   398 net.cpp:259] Setting up conv3\n",
            "I0902 12:59:43.655488   398 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
            "I0902 12:59:43.655515   398 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
            "I0902 12:59:43.655535   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.655558   398 net.cpp:199] Created Layer relu3 (10)\n",
            "I0902 12:59:43.655575   398 net.cpp:571] relu3 <- conv3\n",
            "I0902 12:59:43.655592   398 net.cpp:526] relu3 -> conv3 (in-place)\n",
            "I0902 12:59:43.655616   398 net.cpp:259] Setting up relu3\n",
            "I0902 12:59:43.655632   398 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
            "I0902 12:59:43.655648   398 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
            "I0902 12:59:43.655665   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.655704   398 net.cpp:199] Created Layer conv4 (11)\n",
            "I0902 12:59:43.655717   398 net.cpp:571] conv4 <- conv3\n",
            "I0902 12:59:43.655735   398 net.cpp:541] conv4 -> conv4\n",
            "I0902 12:59:43.668560   398 net.cpp:259] Setting up conv4\n",
            "I0902 12:59:43.668603   398 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
            "I0902 12:59:43.668663   398 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
            "I0902 12:59:43.668682   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.668707   398 net.cpp:199] Created Layer relu4 (12)\n",
            "I0902 12:59:43.668723   398 net.cpp:571] relu4 <- conv4\n",
            "I0902 12:59:43.668742   398 net.cpp:526] relu4 -> conv4 (in-place)\n",
            "I0902 12:59:43.668764   398 net.cpp:259] Setting up relu4\n",
            "I0902 12:59:43.668781   398 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
            "I0902 12:59:43.668797   398 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
            "I0902 12:59:43.668813   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.668851   398 net.cpp:199] Created Layer conv5 (13)\n",
            "I0902 12:59:43.668865   398 net.cpp:571] conv5 <- conv4\n",
            "I0902 12:59:43.668884   398 net.cpp:541] conv5 -> conv5\n",
            "I0902 12:59:43.677218   398 net.cpp:259] Setting up conv5\n",
            "I0902 12:59:43.677253   398 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
            "I0902 12:59:43.677284   398 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
            "I0902 12:59:43.677301   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.677320   398 net.cpp:199] Created Layer relu5 (14)\n",
            "I0902 12:59:43.677335   398 net.cpp:571] relu5 <- conv5\n",
            "I0902 12:59:43.677353   398 net.cpp:526] relu5 -> conv5 (in-place)\n",
            "I0902 12:59:43.677376   398 net.cpp:259] Setting up relu5\n",
            "I0902 12:59:43.677390   398 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
            "I0902 12:59:43.677407   398 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
            "I0902 12:59:43.677423   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.677450   398 net.cpp:199] Created Layer pool5 (15)\n",
            "I0902 12:59:43.677464   398 net.cpp:571] pool5 <- conv5\n",
            "I0902 12:59:43.677480   398 net.cpp:541] pool5 -> pool5\n",
            "I0902 12:59:43.677565   398 net.cpp:259] Setting up pool5\n",
            "I0902 12:59:43.677587   398 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
            "I0902 12:59:43.677603   398 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
            "I0902 12:59:43.677620   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:43.677646   398 net.cpp:199] Created Layer fc6 (16)\n",
            "I0902 12:59:43.677660   398 net.cpp:571] fc6 <- pool5\n",
            "I0902 12:59:43.677676   398 net.cpp:541] fc6 -> fc6\n",
            "I0902 12:59:44.379125   398 net.cpp:259] Setting up fc6\n",
            "I0902 12:59:44.379178   398 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
            "I0902 12:59:44.379211   398 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
            "I0902 12:59:44.379230   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:44.379243   398 net.cpp:199] Created Layer relu6 (17)\n",
            "I0902 12:59:44.379256   398 net.cpp:571] relu6 <- fc6\n",
            "I0902 12:59:44.379267   398 net.cpp:526] relu6 -> fc6 (in-place)\n",
            "I0902 12:59:44.379289   398 net.cpp:259] Setting up relu6\n",
            "I0902 12:59:44.379302   398 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
            "I0902 12:59:44.379308   398 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
            "I0902 12:59:44.379323   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:44.379338   398 net.cpp:199] Created Layer drop6 (18)\n",
            "I0902 12:59:44.379348   398 net.cpp:571] drop6 <- fc6\n",
            "I0902 12:59:44.379354   398 net.cpp:526] drop6 -> fc6 (in-place)\n",
            "I0902 12:59:44.413919   398 net.cpp:259] Setting up drop6\n",
            "I0902 12:59:44.413962   398 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
            "I0902 12:59:44.413980   398 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
            "I0902 12:59:44.413990   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:44.414011   398 net.cpp:199] Created Layer fc7 (19)\n",
            "I0902 12:59:44.414052   398 net.cpp:571] fc7 <- fc6\n",
            "I0902 12:59:44.414062   398 net.cpp:541] fc7 -> fc7\n",
            "I0902 12:59:44.726387   398 net.cpp:259] Setting up fc7\n",
            "I0902 12:59:44.726440   398 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
            "I0902 12:59:44.726471   398 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
            "I0902 12:59:44.726490   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:44.726513   398 net.cpp:199] Created Layer relu7 (20)\n",
            "I0902 12:59:44.726531   398 net.cpp:571] relu7 <- fc7\n",
            "I0902 12:59:44.726549   398 net.cpp:526] relu7 -> fc7 (in-place)\n",
            "I0902 12:59:44.726575   398 net.cpp:259] Setting up relu7\n",
            "I0902 12:59:44.726615   398 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
            "I0902 12:59:44.726635   398 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
            "I0902 12:59:44.726651   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:44.726677   398 net.cpp:199] Created Layer drop7 (21)\n",
            "I0902 12:59:44.726691   398 net.cpp:571] drop7 <- fc7\n",
            "I0902 12:59:44.726709   398 net.cpp:526] drop7 -> fc7 (in-place)\n",
            "I0902 12:59:44.761570   398 net.cpp:259] Setting up drop7\n",
            "I0902 12:59:44.761620   398 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
            "I0902 12:59:44.761646   398 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
            "I0902 12:59:44.761667   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:44.761699   398 net.cpp:199] Created Layer fc8 (22)\n",
            "I0902 12:59:44.761716   398 net.cpp:571] fc8 <- fc7\n",
            "I0902 12:59:44.761731   398 net.cpp:541] fc8 -> fc8\n",
            "I0902 12:59:44.762841   398 net.cpp:259] Setting up fc8\n",
            "I0902 12:59:44.762868   398 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
            "I0902 12:59:44.762895   398 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
            "I0902 12:59:44.762909   398 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:44.762926   398 net.cpp:199] Created Layer softmax (23)\n",
            "I0902 12:59:44.762938   398 net.cpp:571] softmax <- fc8\n",
            "I0902 12:59:44.762945   398 net.cpp:541] softmax -> softmax\n",
            "I0902 12:59:44.763034   398 net.cpp:259] Setting up softmax\n",
            "I0902 12:59:44.763051   398 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
            "I0902 12:59:44.763061   398 net.cpp:337] softmax does not need backward computation.\n",
            "I0902 12:59:44.763072   398 net.cpp:337] fc8 does not need backward computation.\n",
            "I0902 12:59:44.763077   398 net.cpp:337] drop7 does not need backward computation.\n",
            "I0902 12:59:44.763089   398 net.cpp:337] relu7 does not need backward computation.\n",
            "I0902 12:59:44.763094   398 net.cpp:337] fc7 does not need backward computation.\n",
            "I0902 12:59:44.763105   398 net.cpp:337] drop6 does not need backward computation.\n",
            "I0902 12:59:44.763111   398 net.cpp:337] relu6 does not need backward computation.\n",
            "I0902 12:59:44.763119   398 net.cpp:337] fc6 does not need backward computation.\n",
            "I0902 12:59:44.763128   398 net.cpp:337] pool5 does not need backward computation.\n",
            "I0902 12:59:44.763140   398 net.cpp:337] relu5 does not need backward computation.\n",
            "I0902 12:59:44.763156   398 net.cpp:337] conv5 does not need backward computation.\n",
            "I0902 12:59:44.763172   398 net.cpp:337] relu4 does not need backward computation.\n",
            "I0902 12:59:44.763187   398 net.cpp:337] conv4 does not need backward computation.\n",
            "I0902 12:59:44.763202   398 net.cpp:337] relu3 does not need backward computation.\n",
            "I0902 12:59:44.763217   398 net.cpp:337] conv3 does not need backward computation.\n",
            "I0902 12:59:44.763234   398 net.cpp:337] pool2 does not need backward computation.\n",
            "I0902 12:59:44.763249   398 net.cpp:337] norm2 does not need backward computation.\n",
            "I0902 12:59:44.763265   398 net.cpp:337] relu2 does not need backward computation.\n",
            "I0902 12:59:44.763280   398 net.cpp:337] conv2 does not need backward computation.\n",
            "I0902 12:59:44.763296   398 net.cpp:337] pool1 does not need backward computation.\n",
            "I0902 12:59:44.763340   398 net.cpp:337] norm1 does not need backward computation.\n",
            "I0902 12:59:44.763357   398 net.cpp:337] relu1 does not need backward computation.\n",
            "I0902 12:59:44.763372   398 net.cpp:337] conv1 does not need backward computation.\n",
            "I0902 12:59:44.763389   398 net.cpp:337] input does not need backward computation.\n",
            "I0902 12:59:44.763403   398 net.cpp:379] This network produces output softmax\n",
            "I0902 12:59:44.763444   398 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
            "I0902 12:59:44.763459   398 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
            "I0902 12:59:44.763474   398 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
            "I0902 12:59:44.763489   398 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
            "I0902 12:59:44.763504   398 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
            "I0902 12:59:44.763520   398 net.cpp:420] Network initialization done.\n",
            "I0902 12:59:44.898447   398 net.cpp:1129] Ignoring source layer train-data\n",
            "I0902 12:59:44.898492   398 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
            "I0902 12:59:44.898638   398 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
            "I0902 12:59:44.898656   398 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
            "I0902 12:59:44.898667   398 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
            "I0902 12:59:44.898681   398 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
            "I0902 12:59:44.898923   398 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
            "I0902 12:59:44.898941   398 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
            "I0902 12:59:44.898957   398 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
            "I0902 12:59:44.898970   398 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
            "I0902 12:59:44.899561   398 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
            "I0902 12:59:44.899579   398 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
            "I0902 12:59:44.900039   398 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
            "I0902 12:59:44.900053   398 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
            "I0902 12:59:44.900372   398 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
            "I0902 12:59:44.900385   398 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
            "I0902 12:59:44.900393   398 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
            "I0902 12:59:44.923893   398 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
            "I0902 12:59:44.923933   398 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
            "I0902 12:59:44.923951   398 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
            "I0902 12:59:44.934360   398 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
            "I0902 12:59:44.934393   398 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
            "I0902 12:59:44.934410   398 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
            "I0902 12:59:44.934450   398 net.cpp:1129] Ignoring source layer loss\n",
            "whale\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj9J-VgPVfrj",
        "colab_type": "code",
        "colab": {},
        "outputId": "84a4082e-4c94-4b81-d7ca-b59bc623ee63"
      },
      "source": [
        "!python submission.py '/dli/data/whale/data/train/not_face/w_1.jpg'  #This should return \"not whale\" at the very bottom"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0902 12:59:54.811811   413 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
            "I0902 12:59:54.812537   413 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11790385152, dev_info[0]: total=11996954624 free=11790385152\n",
            "W0902 12:59:54.812605   413 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
            "W0902 12:59:54.812742   413 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
            "W0902 12:59:54.812759   413 _caffe.cpp:175] Net('/dli/data/digits/20190902-120542-fbb4/deploy.prototxt', 1, weights='/dli/data/digits/20190902-120542-fbb4/snapshot_iter_1620.caffemodel')\n",
            "I0902 12:59:54.813097   413 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20190902-120542-fbb4/deploy.prototxt\n",
            "I0902 12:59:54.813130   413 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
            "W0902 12:59:54.813143   413 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
            "I0902 12:59:54.823228   413 net.cpp:79] Initializing net from parameters: \n",
            "state {\n",
            "  phase: TEST\n",
            "  level: 0\n",
            "}\n",
            "layer {\n",
            "  name: \"input\"\n",
            "  type: \"Input\"\n",
            "  top: \"data\"\n",
            "  input_param {\n",
            "    shape {\n",
            "      dim: 1\n",
            "      dim: 3\n",
            "      dim: 227\n",
            "      dim: 227\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv1\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"data\"\n",
            "  top: \"conv1\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 96\n",
            "    kernel_size: 11\n",
            "    stride: 4\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu1\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"conv1\"\n",
            "}\n",
            "layer {\n",
            "  name: \"norm1\"\n",
            "  type: \"LRN\"\n",
            "  bottom: \"conv1\"\n",
            "  top: \"norm1\"\n",
            "  lrn_param {\n",
            "    local_size: 5\n",
            "    alpha: 0.0001\n",
            "    beta: 0.75\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool1\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"norm1\"\n",
            "  top: \"pool1\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv2\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool1\"\n",
            "  top: \"conv2\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    pad: 2\n",
            "    kernel_size: 5\n",
            "    group: 2\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0.1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu2\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"conv2\"\n",
            "}\n",
            "layer {\n",
            "  name: \"norm2\"\n",
            "  type: \"LRN\"\n",
            "  bottom: \"conv2\"\n",
            "  top: \"norm2\"\n",
            "  lrn_param {\n",
            "    local_size: 5\n",
            "    alpha: 0.0001\n",
            "    beta: 0.75\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"pool2\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"norm2\"\n",
            "  top: \"pool2\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"conv3\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"pool2\"\n",
            "  top: \"conv3\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 384\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu3\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv3\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv4\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"conv3\"\n",
            "  top: \"conv4\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 384\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    group: 2\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0.1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu4\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv4\"\n",
            "  top: \"conv4\"\n",
            "}\n",
            "layer {\n",
            "  name: \"conv5\"\n",
            "  type: \"Convolution\"\n",
            "  bottom: \"conv4\"\n",
            "  top: \"conv5\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  convolution_param {\n",
            "    num_output: 256\n",
            "    pad: 1\n",
            "    kernel_size: 3\n",
            "    group: 2\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0.1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu5\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"conv5\"\n",
            "  top: \"conv5\"\n",
            "}\n",
            "layer {\n",
            "  name: \"pool5\"\n",
            "  type: \"Pooling\"\n",
            "  bottom: \"conv5\"\n",
            "  top: \"pool5\"\n",
            "  pooling_param {\n",
            "    pool: MAX\n",
            "    kernel_size: 3\n",
            "    stride: 2\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"fc6\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"pool5\"\n",
            "  top: \"fc6\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 4096\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.005\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0.1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu6\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"fc6\"\n",
            "  top: \"fc6\"\n",
            "}\n",
            "layer {\n",
            "  name: \"drop6\"\n",
            "  type: \"Dropout\"\n",
            "  bottom: \"fc6\"\n",
            "  top: \"fc6\"\n",
            "  dropout_param {\n",
            "    dropout_ratio: 0.5\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"fc7\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"fc6\"\n",
            "  top: \"fc7\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 4096\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.005\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0.1\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"relu7\"\n",
            "  type: \"ReLU\"\n",
            "  bottom: \"fc7\"\n",
            "  top: \"fc7\"\n",
            "}\n",
            "layer {\n",
            "  name: \"drop7\"\n",
            "  type: \"Dropout\"\n",
            "  bottom: \"fc7\"\n",
            "  top: \"fc7\"\n",
            "  dropout_param {\n",
            "    dropout_ratio: 0.5\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"fc8\"\n",
            "  type: \"InnerProduct\"\n",
            "  bottom: \"fc7\"\n",
            "  top: \"fc8\"\n",
            "  param {\n",
            "    lr_mult: 1\n",
            "    decay_mult: 1\n",
            "  }\n",
            "  param {\n",
            "    lr_mult: 2\n",
            "    decay_mult: 0\n",
            "  }\n",
            "  inner_product_param {\n",
            "    num_output: 2\n",
            "    weight_filler {\n",
            "      type: \"gaussian\"\n",
            "      std: 0.01\n",
            "    }\n",
            "    bias_filler {\n",
            "      type: \"constant\"\n",
            "      value: 0\n",
            "    }\n",
            "  }\n",
            "}\n",
            "layer {\n",
            "  name: \"softmax\"\n",
            "  type: \"Softmax\"\n",
            "  bottom: \"fc8\"\n",
            "  top: \"softmax\"\n",
            "}\n",
            "I0902 12:59:54.823719   413 net.cpp:109] Using FLOAT as default forward math type\n",
            "I0902 12:59:54.823736   413 net.cpp:115] Using FLOAT as default backward math type\n",
            "I0902 12:59:54.823745   413 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
            "I0902 12:59:54.823753   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:54.823766   413 net.cpp:199] Created Layer input (0)\n",
            "I0902 12:59:54.823777   413 net.cpp:541] input -> data\n",
            "I0902 12:59:54.824661   413 net.cpp:259] Setting up input\n",
            "I0902 12:59:54.824703   413 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
            "I0902 12:59:54.824728   413 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
            "I0902 12:59:54.824748   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:54.824798   413 net.cpp:199] Created Layer conv1 (1)\n",
            "I0902 12:59:54.824820   413 net.cpp:571] conv1 <- data\n",
            "I0902 12:59:54.824842   413 net.cpp:541] conv1 -> conv1\n",
            "I0902 12:59:55.384096   413 net.cpp:259] Setting up conv1\n",
            "I0902 12:59:55.384146   413 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
            "I0902 12:59:55.384183   413 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
            "I0902 12:59:55.384203   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.384223   413 net.cpp:199] Created Layer relu1 (2)\n",
            "I0902 12:59:55.384236   413 net.cpp:571] relu1 <- conv1\n",
            "I0902 12:59:55.384251   413 net.cpp:526] relu1 -> conv1 (in-place)\n",
            "I0902 12:59:55.384276   413 net.cpp:259] Setting up relu1\n",
            "I0902 12:59:55.384290   413 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
            "I0902 12:59:55.384302   413 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
            "I0902 12:59:55.384315   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.384342   413 net.cpp:199] Created Layer norm1 (3)\n",
            "I0902 12:59:55.384354   413 net.cpp:571] norm1 <- conv1\n",
            "I0902 12:59:55.384366   413 net.cpp:541] norm1 -> norm1\n",
            "I0902 12:59:55.384428   413 net.cpp:259] Setting up norm1\n",
            "I0902 12:59:55.384446   413 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
            "I0902 12:59:55.384454   413 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
            "I0902 12:59:55.384466   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.384511   413 net.cpp:199] Created Layer pool1 (4)\n",
            "I0902 12:59:55.384524   413 net.cpp:571] pool1 <- norm1\n",
            "I0902 12:59:55.384537   413 net.cpp:541] pool1 -> pool1\n",
            "I0902 12:59:55.384609   413 net.cpp:259] Setting up pool1\n",
            "I0902 12:59:55.384627   413 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
            "I0902 12:59:55.384640   413 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
            "I0902 12:59:55.384652   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.384676   413 net.cpp:199] Created Layer conv2 (5)\n",
            "I0902 12:59:55.384688   413 net.cpp:571] conv2 <- pool1\n",
            "I0902 12:59:55.384696   413 net.cpp:541] conv2 -> conv2\n",
            "I0902 12:59:55.392107   413 net.cpp:259] Setting up conv2\n",
            "I0902 12:59:55.392136   413 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
            "I0902 12:59:55.392158   413 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
            "I0902 12:59:55.392174   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.392196   413 net.cpp:199] Created Layer relu2 (6)\n",
            "I0902 12:59:55.392210   413 net.cpp:571] relu2 <- conv2\n",
            "I0902 12:59:55.392222   413 net.cpp:526] relu2 -> conv2 (in-place)\n",
            "I0902 12:59:55.392238   413 net.cpp:259] Setting up relu2\n",
            "I0902 12:59:55.392251   413 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
            "I0902 12:59:55.392263   413 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
            "I0902 12:59:55.392275   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.392292   413 net.cpp:199] Created Layer norm2 (7)\n",
            "I0902 12:59:55.392304   413 net.cpp:571] norm2 <- conv2\n",
            "I0902 12:59:55.392316   413 net.cpp:541] norm2 -> norm2\n",
            "I0902 12:59:55.392374   413 net.cpp:259] Setting up norm2\n",
            "I0902 12:59:55.392392   413 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
            "I0902 12:59:55.392405   413 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
            "I0902 12:59:55.392418   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.392429   413 net.cpp:199] Created Layer pool2 (8)\n",
            "I0902 12:59:55.392441   413 net.cpp:571] pool2 <- norm2\n",
            "I0902 12:59:55.392448   413 net.cpp:541] pool2 -> pool2\n",
            "I0902 12:59:55.392508   413 net.cpp:259] Setting up pool2\n",
            "I0902 12:59:55.392524   413 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
            "I0902 12:59:55.392539   413 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
            "I0902 12:59:55.392549   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.392570   413 net.cpp:199] Created Layer conv3 (9)\n",
            "I0902 12:59:55.392582   413 net.cpp:571] conv3 <- pool2\n",
            "I0902 12:59:55.392596   413 net.cpp:541] conv3 -> conv3\n",
            "I0902 12:59:55.408460   413 net.cpp:259] Setting up conv3\n",
            "I0902 12:59:55.408488   413 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
            "I0902 12:59:55.408511   413 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
            "I0902 12:59:55.408526   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.408542   413 net.cpp:199] Created Layer relu3 (10)\n",
            "I0902 12:59:55.408555   413 net.cpp:571] relu3 <- conv3\n",
            "I0902 12:59:55.408568   413 net.cpp:526] relu3 -> conv3 (in-place)\n",
            "I0902 12:59:55.408584   413 net.cpp:259] Setting up relu3\n",
            "I0902 12:59:55.408597   413 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
            "I0902 12:59:55.408610   413 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
            "I0902 12:59:55.408622   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.408643   413 net.cpp:199] Created Layer conv4 (11)\n",
            "I0902 12:59:55.408654   413 net.cpp:571] conv4 <- conv3\n",
            "I0902 12:59:55.408668   413 net.cpp:541] conv4 -> conv4\n",
            "I0902 12:59:55.421125   413 net.cpp:259] Setting up conv4\n",
            "I0902 12:59:55.421152   413 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
            "I0902 12:59:55.421197   413 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
            "I0902 12:59:55.421211   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.421226   413 net.cpp:199] Created Layer relu4 (12)\n",
            "I0902 12:59:55.421239   413 net.cpp:571] relu4 <- conv4\n",
            "I0902 12:59:55.421252   413 net.cpp:526] relu4 -> conv4 (in-place)\n",
            "I0902 12:59:55.421268   413 net.cpp:259] Setting up relu4\n",
            "I0902 12:59:55.421281   413 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
            "I0902 12:59:55.421294   413 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
            "I0902 12:59:55.421305   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.421329   413 net.cpp:199] Created Layer conv5 (13)\n",
            "I0902 12:59:55.421340   413 net.cpp:571] conv5 <- conv4\n",
            "I0902 12:59:55.421353   413 net.cpp:541] conv5 -> conv5\n",
            "I0902 12:59:55.429505   413 net.cpp:259] Setting up conv5\n",
            "I0902 12:59:55.429533   413 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
            "I0902 12:59:55.429550   413 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
            "I0902 12:59:55.429565   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.429577   413 net.cpp:199] Created Layer relu5 (14)\n",
            "I0902 12:59:55.429589   413 net.cpp:571] relu5 <- conv5\n",
            "I0902 12:59:55.429602   413 net.cpp:526] relu5 -> conv5 (in-place)\n",
            "I0902 12:59:55.429620   413 net.cpp:259] Setting up relu5\n",
            "I0902 12:59:55.429632   413 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
            "I0902 12:59:55.429644   413 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
            "I0902 12:59:55.429656   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.429673   413 net.cpp:199] Created Layer pool5 (15)\n",
            "I0902 12:59:55.429684   413 net.cpp:571] pool5 <- conv5\n",
            "I0902 12:59:55.429697   413 net.cpp:541] pool5 -> pool5\n",
            "I0902 12:59:55.429769   413 net.cpp:259] Setting up pool5\n",
            "I0902 12:59:55.429786   413 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
            "I0902 12:59:55.429795   413 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
            "I0902 12:59:55.429802   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:55.429818   413 net.cpp:199] Created Layer fc6 (16)\n",
            "I0902 12:59:55.429831   413 net.cpp:571] fc6 <- pool5\n",
            "I0902 12:59:55.429838   413 net.cpp:541] fc6 -> fc6\n",
            "I0902 12:59:56.131012   413 net.cpp:259] Setting up fc6\n",
            "I0902 12:59:56.131067   413 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
            "I0902 12:59:56.131091   413 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
            "I0902 12:59:56.131109   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:56.131129   413 net.cpp:199] Created Layer relu6 (17)\n",
            "I0902 12:59:56.131144   413 net.cpp:571] relu6 <- fc6\n",
            "I0902 12:59:56.131155   413 net.cpp:526] relu6 -> fc6 (in-place)\n",
            "I0902 12:59:56.131176   413 net.cpp:259] Setting up relu6\n",
            "I0902 12:59:56.131189   413 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
            "I0902 12:59:56.131196   413 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
            "I0902 12:59:56.131209   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:56.131223   413 net.cpp:199] Created Layer drop6 (18)\n",
            "I0902 12:59:56.131234   413 net.cpp:571] drop6 <- fc6\n",
            "I0902 12:59:56.131242   413 net.cpp:526] drop6 -> fc6 (in-place)\n",
            "I0902 12:59:56.165967   413 net.cpp:259] Setting up drop6\n",
            "I0902 12:59:56.166013   413 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
            "I0902 12:59:56.166028   413 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
            "I0902 12:59:56.166045   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:56.166064   413 net.cpp:199] Created Layer fc7 (19)\n",
            "I0902 12:59:56.166105   413 net.cpp:571] fc7 <- fc6\n",
            "I0902 12:59:56.166119   413 net.cpp:541] fc7 -> fc7\n",
            "I0902 12:59:56.478849   413 net.cpp:259] Setting up fc7\n",
            "I0902 12:59:56.478901   413 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
            "I0902 12:59:56.478925   413 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
            "I0902 12:59:56.478943   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:56.478960   413 net.cpp:199] Created Layer relu7 (20)\n",
            "I0902 12:59:56.478974   413 net.cpp:571] relu7 <- fc7\n",
            "I0902 12:59:56.478984   413 net.cpp:526] relu7 -> fc7 (in-place)\n",
            "I0902 12:59:56.479005   413 net.cpp:259] Setting up relu7\n",
            "I0902 12:59:56.479017   413 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
            "I0902 12:59:56.479025   413 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
            "I0902 12:59:56.479038   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:56.479051   413 net.cpp:199] Created Layer drop7 (21)\n",
            "I0902 12:59:56.479061   413 net.cpp:571] drop7 <- fc7\n",
            "I0902 12:59:56.479068   413 net.cpp:526] drop7 -> fc7 (in-place)\n",
            "I0902 12:59:56.513734   413 net.cpp:259] Setting up drop7\n",
            "I0902 12:59:56.513777   413 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
            "I0902 12:59:56.513792   413 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
            "I0902 12:59:56.513808   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:56.513823   413 net.cpp:199] Created Layer fc8 (22)\n",
            "I0902 12:59:56.513837   413 net.cpp:571] fc8 <- fc7\n",
            "I0902 12:59:56.513849   413 net.cpp:541] fc8 -> fc8\n",
            "I0902 12:59:56.514945   413 net.cpp:259] Setting up fc8\n",
            "I0902 12:59:56.514969   413 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
            "I0902 12:59:56.514989   413 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
            "I0902 12:59:56.515003   413 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
            "I0902 12:59:56.515029   413 net.cpp:199] Created Layer softmax (23)\n",
            "I0902 12:59:56.515043   413 net.cpp:571] softmax <- fc8\n",
            "I0902 12:59:56.515056   413 net.cpp:541] softmax -> softmax\n",
            "I0902 12:59:56.515151   413 net.cpp:259] Setting up softmax\n",
            "I0902 12:59:56.515169   413 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
            "I0902 12:59:56.515182   413 net.cpp:337] softmax does not need backward computation.\n",
            "I0902 12:59:56.515198   413 net.cpp:337] fc8 does not need backward computation.\n",
            "I0902 12:59:56.515209   413 net.cpp:337] drop7 does not need backward computation.\n",
            "I0902 12:59:56.515219   413 net.cpp:337] relu7 does not need backward computation.\n",
            "I0902 12:59:56.515229   413 net.cpp:337] fc7 does not need backward computation.\n",
            "I0902 12:59:56.515236   413 net.cpp:337] drop6 does not need backward computation.\n",
            "I0902 12:59:56.515246   413 net.cpp:337] relu6 does not need backward computation.\n",
            "I0902 12:59:56.515254   413 net.cpp:337] fc6 does not need backward computation.\n",
            "I0902 12:59:56.515264   413 net.cpp:337] pool5 does not need backward computation.\n",
            "I0902 12:59:56.515270   413 net.cpp:337] relu5 does not need backward computation.\n",
            "I0902 12:59:56.515281   413 net.cpp:337] conv5 does not need backward computation.\n",
            "I0902 12:59:56.515288   413 net.cpp:337] relu4 does not need backward computation.\n",
            "I0902 12:59:56.515300   413 net.cpp:337] conv4 does not need backward computation.\n",
            "I0902 12:59:56.515311   413 net.cpp:337] relu3 does not need backward computation.\n",
            "I0902 12:59:56.515323   413 net.cpp:337] conv3 does not need backward computation.\n",
            "I0902 12:59:56.515336   413 net.cpp:337] pool2 does not need backward computation.\n",
            "I0902 12:59:56.515348   413 net.cpp:337] norm2 does not need backward computation.\n",
            "I0902 12:59:56.515359   413 net.cpp:337] relu2 does not need backward computation.\n",
            "I0902 12:59:56.515372   413 net.cpp:337] conv2 does not need backward computation.\n",
            "I0902 12:59:56.515383   413 net.cpp:337] pool1 does not need backward computation.\n",
            "I0902 12:59:56.515421   413 net.cpp:337] norm1 does not need backward computation.\n",
            "I0902 12:59:56.515434   413 net.cpp:337] relu1 does not need backward computation.\n",
            "I0902 12:59:56.515445   413 net.cpp:337] conv1 does not need backward computation.\n",
            "I0902 12:59:56.515457   413 net.cpp:337] input does not need backward computation.\n",
            "I0902 12:59:56.515467   413 net.cpp:379] This network produces output softmax\n",
            "I0902 12:59:56.515497   413 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
            "I0902 12:59:56.515511   413 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
            "I0902 12:59:56.515517   413 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
            "I0902 12:59:56.515527   413 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
            "I0902 12:59:56.515533   413 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
            "I0902 12:59:56.515543   413 net.cpp:420] Network initialization done.\n",
            "I0902 12:59:56.649806   413 net.cpp:1129] Ignoring source layer train-data\n",
            "I0902 12:59:56.649847   413 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
            "I0902 12:59:56.649961   413 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
            "I0902 12:59:56.649976   413 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
            "I0902 12:59:56.649994   413 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
            "I0902 12:59:56.650005   413 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
            "I0902 12:59:56.650243   413 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
            "I0902 12:59:56.650259   413 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
            "I0902 12:59:56.650264   413 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
            "I0902 12:59:56.650274   413 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
            "I0902 12:59:56.650903   413 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
            "I0902 12:59:56.650919   413 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
            "I0902 12:59:56.651332   413 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
            "I0902 12:59:56.651346   413 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
            "I0902 12:59:56.651648   413 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
            "I0902 12:59:56.651661   413 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
            "I0902 12:59:56.651669   413 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
            "I0902 12:59:56.674546   413 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
            "I0902 12:59:56.674593   413 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
            "I0902 12:59:56.674605   413 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
            "I0902 12:59:56.684957   413 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
            "I0902 12:59:56.684988   413 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
            "I0902 12:59:56.684994   413 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
            "I0902 12:59:56.685025   413 net.cpp:1129] Ignoring source layer loss\n",
            "not whale\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGEBgm2JVfrl",
        "colab_type": "code",
        "colab": {},
        "outputId": "0736a5b9-965f-4296-e809-2ee8763048c7"
      },
      "source": [
        "!ls [directorypath] prints the files in a given directory"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '[directorypath]': No such file or directory\r\n",
            "ls: cannot access 'prints': No such file or directory\r\n",
            "ls: cannot access 'the': No such file or directory\r\n",
            "ls: cannot access 'files': No such file or directory\r\n",
            "ls: cannot access 'in': No such file or directory\r\n",
            "ls: cannot access 'a': No such file or directory\r\n",
            "ls: cannot access 'given': No such file or directory\r\n",
            "ls: cannot access 'directory': No such file or directory\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fGkTe5VVfrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOSlrQxnVfro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQah63TGVfrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvY6jzi7Vfrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dAXIYugVfrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}